{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this python script processes the twitter data from nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "td = timedelta (days = 0, hours = 6 , minutes = 48)  # difference between laptop time and realtime\n",
    "Anfang = datetime.now()\n",
    "Start = Anfang + td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as prp\n",
    "\n",
    "def normalize_text(doc):\n",
    "    tokens = []\n",
    "    for sent in doc.sents:\n",
    "        sent = str(sent)\n",
    "        sent = sent.replace('\\r', ' ').replace('\\n', ' ')\n",
    "        lower = sent.lower()\n",
    "        nopunc = lower.translate(translator)\n",
    "        words = nopunc.split()\n",
    "        nostop = [w for w in words if w not in stoplist]\n",
    "        no_numbers = [w if not w.isdigit() else '#' for w in nostop]\n",
    "        stemmed = [stemmer.stem(w) for w in no_numbers]\n",
    "        tokens += stemmed\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "fids = twitter_samples.fileids()\n",
    "strs = twitter_samples.strings(fids[2])\n",
    "#len(strs) # 20000\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tweet = re.sub(r'@[A-Za-z0-9]+', '', tweet)\n",
    "    tweet = re.sub(r'['+string.punctuation+']+', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def clean_tweet2(tweet):\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r' #[\\w]+ ', ' ', tweet)\n",
    "    tweet = re.sub(r'@[A-Za-z0-9]+', '', tweet)\n",
    "#    tweet = re.sub(r'['+string.punctuation+']+', '', tweet)\n",
    "    tweet = re.sub(r' ['+string.punctuation+']+ ', ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "nlp2 = spacy.load('en_core_web_sm')\n",
    "\n",
    "dftw = pd.DataFrame(index = range(0,0), columns=['leng', 'nwords', 'ntoks', 'nverbs', 'npast', 'npresent', 'nfuture', 'nfpast', 'nfpresent', 'nffuture', 'tw'], dtype = int)\n",
    "\n",
    "for col in ['leng', 'nwords', 'ntoks', 'nverbs', 'npast', 'npresent', 'nfuture', 'nfpast', 'nfpresent', 'nffuture']:\n",
    "    dftw[col] = dftw[col].astype(int)\n",
    "\n",
    "dftw['tw'] = dftw['tw'].astype(object)\n",
    "\n",
    "twfids = twitter_samples.fileids()\n",
    "strs = twitter_samples.strings(twfids[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jetzt:2019-06-29 21:28:11.510813  i:0 ... interim checkpointing to pj_dftw_full.20190629_212811.pkl\n",
      "jetzt:2019-06-29 21:28:59.560156  i:579 ... interim checkpointing to pj_dftw_full.20190629_212859.pkl\n",
      "jetzt:2019-06-29 21:29:40.453085  i:1158 ... interim checkpointing to pj_dftw_full.20190629_212940.pkl\n",
      "jetzt:2019-06-29 21:30:21.174419  i:1737 ... interim checkpointing to pj_dftw_full.20190629_213021.pkl\n",
      "jetzt:2019-06-29 21:31:01.800197  i:2316 ... interim checkpointing to pj_dftw_full.20190629_213101.pkl\n",
      "jetzt:2019-06-29 21:31:42.885154  i:2895 ... interim checkpointing to pj_dftw_full.20190629_213142.pkl\n",
      "jetzt:2019-06-29 21:32:23.914505  i:3474 ... interim checkpointing to pj_dftw_full.20190629_213223.pkl\n",
      "jetzt:2019-06-29 21:33:06.753227  i:4053 ... interim checkpointing to pj_dftw_full.20190629_213306.pkl\n",
      "jetzt:2019-06-29 21:33:52.175291  i:4632 ... interim checkpointing to pj_dftw_full.20190629_213352.pkl\n",
      "jetzt:2019-06-29 21:34:45.066815  i:5211 ... interim checkpointing to pj_dftw_full.20190629_213445.pkl\n",
      "jetzt:2019-06-29 21:35:34.816984  i:5790 ... interim checkpointing to pj_dftw_full.20190629_213534.pkl\n",
      "jetzt:2019-06-29 21:36:15.933291  i:6369 ... interim checkpointing to pj_dftw_full.20190629_213615.pkl\n",
      "jetzt:2019-06-29 21:36:57.316767  i:6948 ... interim checkpointing to pj_dftw_full.20190629_213657.pkl\n",
      "jetzt:2019-06-29 21:37:39.054031  i:7527 ... interim checkpointing to pj_dftw_full.20190629_213739.pkl\n",
      "jetzt:2019-06-29 21:38:20.692605  i:8106 ... interim checkpointing to pj_dftw_full.20190629_213820.pkl\n",
      "jetzt:2019-06-29 21:39:02.864875  i:8685 ... interim checkpointing to pj_dftw_full.20190629_213902.pkl\n",
      "jetzt:2019-06-29 21:39:45.612766  i:9264 ... interim checkpointing to pj_dftw_full.20190629_213945.pkl\n",
      "jetzt:2019-06-29 21:40:40.730806  i:9843 ... interim checkpointing to pj_dftw_full.20190629_214040.pkl\n",
      "jetzt:2019-06-29 21:41:56.456921  i:10422 ... interim checkpointing to pj_dftw_full.20190629_214156.pkl\n",
      "jetzt:2019-06-29 21:42:46.946764  i:11001 ... interim checkpointing to pj_dftw_full.20190629_214246.pkl\n",
      "jetzt:2019-06-29 21:43:37.150012  i:11580 ... interim checkpointing to pj_dftw_full.20190629_214337.pkl\n",
      "jetzt:2019-06-29 21:44:30.012752  i:12159 ... interim checkpointing to pj_dftw_full.20190629_214430.pkl\n",
      "jetzt:2019-06-29 21:45:16.622028  i:12738 ... interim checkpointing to pj_dftw_full.20190629_214516.pkl\n",
      "jetzt:2019-06-29 21:46:03.145606  i:13317 ... interim checkpointing to pj_dftw_full.20190629_214603.pkl\n",
      "jetzt:2019-06-29 21:46:52.095976  i:13896 ... interim checkpointing to pj_dftw_full.20190629_214652.pkl\n",
      "jetzt:2019-06-29 21:48:18.415958  i:14475 ... interim checkpointing to pj_dftw_full.20190629_214818.pkl\n",
      "jetzt:2019-06-29 21:49:20.366438  i:15054 ... interim checkpointing to pj_dftw_full.20190629_214920.pkl\n",
      "jetzt:2019-06-29 21:50:21.557927  i:15633 ... interim checkpointing to pj_dftw_full.20190629_215021.pkl\n",
      "jetzt:2019-06-29 21:51:13.326559  i:16212 ... interim checkpointing to pj_dftw_full.20190629_215113.pkl\n",
      "jetzt:2019-06-29 21:52:00.506238  i:16791 ... interim checkpointing to pj_dftw_full.20190629_215200.pkl\n",
      "jetzt:2019-06-29 21:52:47.166198  i:17370 ... interim checkpointing to pj_dftw_full.20190629_215247.pkl\n",
      "jetzt:2019-06-29 21:53:33.548745  i:17949 ... interim checkpointing to pj_dftw_full.20190629_215333.pkl\n",
      "jetzt:2019-06-29 21:54:32.873521  i:18528 ... interim checkpointing to pj_dftw_full.20190629_215432.pkl\n",
      "jetzt:2019-06-29 21:56:00.765182  i:19107 ... interim checkpointing to pj_dftw_full.20190629_215600.pkl\n",
      "jetzt:2019-06-29 21:57:27.654286  i:19686 ... interim checkpointing to pj_dftw_full.20190629_215727.pkl\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(strs)):\n",
    "    twc = prp.clean(strs[i])\n",
    "    dftw.at[i, 'tw'] = twc\n",
    "\n",
    "    dftw.at[i, 'leng'] = len(twc)\n",
    "\n",
    "    doc = nlp2(twc)\n",
    "\n",
    "    cltoks = normalize_text(doc)\n",
    "    ntoks = [str(token).lower() for token in list(doc) if (not token.is_punct) & (not token.is_space) & (not token.is_stop) & (str(token) in cltoks)]\n",
    "    dftw.at[i, 'ntoks'] = len(ntoks)\n",
    "\n",
    "    sentences = [sent.string.strip() for sent in doc.sents]\n",
    "    dftw.at[i, 'nsents'] =  len(sentences)\n",
    "    dftw.at[i, 'nwords'] = len([token for token in doc if not token.is_punct])\n",
    "\n",
    "    dftw.at[i, 'nverbs'] = len([w for w in list(doc) if w.tag_.startswith('V')])\n",
    "\n",
    "    npast, npresent, nfuture, antpast, antpresent, antfuture = spacy_parse(doc)\n",
    "#\n",
    "    dftw.at[i, 'npast'] = npast\n",
    "    dftw.at[i, 'npresent'] = npresent\n",
    "    dftw.at[i, 'nfuture'] = nfuture\n",
    "\n",
    "    dftw.at[i, 'antpast'] = antpast\n",
    "    dftw.at[i, 'antpresent'] = antpresent\n",
    "    dftw.at[i, 'antfuture'] = antfuture\n",
    "\n",
    "    nfpast, nfpresent, nffuture, antfpast, antfpresent, antffuture = liwc_parse(twc)\n",
    "#\n",
    "    dftw.at[i, 'nfpast'] = nfpast\n",
    "    dftw.at[i, 'nfpresent'] = nfpresent\n",
    "    dftw.at[i, 'nffuture'] = nffuture\n",
    "    dftw.at[i, 'antfpast'] = antfpast\n",
    "    dftw.at[i, 'antfpresent'] = antfpresent\n",
    "    dftw.at[i, 'antffuture'] = antffuture\n",
    "\n",
    "    dftw.at[i, 'ldeont'] = deont_parse(twc)\n",
    "    dftw.at[i, 'lmodal'] = modal_parse(twc)\n",
    "#\n",
    "    if (i %579 == 0):\n",
    "        je = datetime.now() + td\n",
    "        pkl_fname = 'pj_dftw_full.' + je.strftime('%Y%m%d_%H%M%S' + \".pkl\")\n",
    "        print (\"jetzt:{0}  i:{1} ... interim checkpointing to {2}\".format(je, i, pkl_fname))\n",
    "        dftw.to_pickle(pkl_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jetzt:2019-06-30 00:56:52.633221  i:19999 ... final checkpointing to pj_dftw_full.20190630_005652.pkl\n"
     ]
    }
   ],
   "source": [
    "je = datetime.now() + td\n",
    "pkl_fname = 'pj_dftw_full.' + je.strftime('%Y%m%d_%H%M%S' + \".pkl\")\n",
    "print (\"jetzt:{0}  i:{1} ... final checkpointing to {2}\".format(je, i, pkl_fname))\n",
    "dftw.to_pickle(pkl_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leng</th>\n",
       "      <th>nwords</th>\n",
       "      <th>ntoks</th>\n",
       "      <th>nverbs</th>\n",
       "      <th>npast</th>\n",
       "      <th>npresent</th>\n",
       "      <th>nfuture</th>\n",
       "      <th>nfpast</th>\n",
       "      <th>nfpresent</th>\n",
       "      <th>nffuture</th>\n",
       "      <th>tw</th>\n",
       "      <th>nsents</th>\n",
       "      <th>antpast</th>\n",
       "      <th>antpresent</th>\n",
       "      <th>antfuture</th>\n",
       "      <th>antfpast</th>\n",
       "      <th>antfpresent</th>\n",
       "      <th>antffuture</th>\n",
       "      <th>ldeont</th>\n",
       "      <th>lmodal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>: Indirect cost of the UK being in the EU is e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VIDEO: Sturgeon on post-election deals</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>: The economy was growing times faster on the ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>: the UKIP east lothian candidate looks about ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>: UKIP's housing spokesman rakes in £800k in h...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    leng  nwords  ntoks  nverbs  npast  npresent  nfuture  nfpast  nfpresent  \\\n",
       "0   99.0    20.0    3.0     5.0    0.0       0.0      0.0     0.0        2.0   \n",
       "1   38.0     6.0    0.0     0.0    0.0       0.0      0.0     0.0        0.0   \n",
       "2  104.0    18.0    3.0     4.0    2.0       0.0      0.0     2.0        2.0   \n",
       "3   71.0    13.0    3.0     2.0    0.0       2.0      0.0     0.0        2.0   \n",
       "4   75.0    13.0    2.0     1.0    0.0       2.0      0.0     1.0        0.0   \n",
       "\n",
       "   nffuture                                                 tw  nsents  \\\n",
       "0       0.0  : Indirect cost of the UK being in the EU is e...     1.0   \n",
       "1       0.0             VIDEO: Sturgeon on post-election deals     1.0   \n",
       "2       0.0  : The economy was growing times faster on the ...     1.0   \n",
       "3       0.0  : the UKIP east lothian candidate looks about ...     1.0   \n",
       "4       0.0  : UKIP's housing spokesman rakes in £800k in h...     1.0   \n",
       "\n",
       "   antpast  antpresent  antfuture  antfpast  antfpresent  antffuture  ldeont  \\\n",
       "0      0.0         0.0        0.0       0.0          1.0         0.0     0.0   \n",
       "1      0.0         0.0        0.0       0.0          0.0         0.0     0.0   \n",
       "2      1.0         0.0        0.0       0.5          0.5         0.0     0.0   \n",
       "3      0.0         1.0        0.0       0.0          1.0         0.0     0.0   \n",
       "4      0.0         1.0        0.0       1.0          0.0         0.0     0.0   \n",
       "\n",
       "   lmodal  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1672.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftw[\"lmodal\"].describe()\n",
    "dftw[\"lmodal\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
